#!/usr/bin/env python
# encoding: utf-8


# code fragments taken from:
# http://docs.tweepy.org/en/v3.5.0/auth_tutorial.html
# https://gist.github.com/yanofsky/5436496
# https://shkspr.mobi/blog/2017/06/easy-tutorial-for-getting-twitter-friends-using-python-tweepy/



import tweepy  # https://github.com/tweepy/tweepy
import csv
import time
from tqdm import tqdm


# store twitter credentials to later access in code

# Twitter API credentials
consumer_key = ''
consumer_secret = ''
access_token = ''
access_secret = ''


def get_all_tweets(screen_name):
    # here the script connects to the Twitter server and authorises with the credentials defined above
    # note tweepy is the package that does this for us
    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
    auth.set_access_token(access_token, access_secret)
    api = tweepy.API(auth)
    # note api is the object on which we can communicate with the Twitter server now

    # the following is mainly based on http://tkang.blogspot.ch/2011/01/tweepy-twitter-api-status-object.html
    # until stated otherwise

    # initialise a list to hold all the tweepy tweets
    alltweets = []

    # make initial request for most recent tweets (200 is the maximum allowed count)
    new_tweets = api.user_timeline(screen_name=screen_name, count=200, tweet_mode='extended')

    # save most recent tweets
    alltweets.extend(new_tweets)

    # save the id of the oldest tweet 
    oldest = alltweets[-1].id - 1

    # keep grabbing tweets until there are no tweets left to grab
    while len(new_tweets) > 0:
        print "getting tweets before %s" % (oldest)

        # all subsequent requests use the max_id param to prevent duplicates
        new_tweets = api.user_timeline(screen_name=screen_name, count=200, max_id=oldest, tweet_mode='extended')

        # save most recent tweets
        alltweets.extend(new_tweets)

        # update the id of the penultimate tweet
        oldest = alltweets[-1].id - 1

        print "...%s tweets downloaded so far" % (len(alltweets))

    # transform the tweepy tweets into a 2D array that will populate the csv
    outtweets=[]
    for tweet in alltweets:
        try:
            try:
                if tweet.retweeted_status:
                    tweetText = tweet.retweeted_status.full_text.encode("utf-8")
                    tweetFavoriteCount = tweet.retweeted_status.favorite_count
            except:
                    tweetText = tweet.full_text.encode("utf-8")
                    tweetFavoriteCount = tweet.favorite_count

            if tweet.in_reply_to_status_id:
                try:
                    replied_to_text = api.get_status(tweet.in_reply_to_status_id,tweet_mode='extended').full_text
                except:
                    replied_to_text = "NA"
            else:
                replied_to_text = "NA";

            # here all the attributes are saved

            tweetData = [tweet.id_str,
                         tweet.created_at,
                         tweetText, tweet.retweet_count,
                         tweetFavoriteCount, tweet.source,
                         'https://twitter.com/' + tweet.author.screen_name.encode("utf-8") + '/status/' +
                         str(tweet.id),
                         tweet.in_reply_to_screen_name,
                         tweet.in_reply_to_status_id,
                         replied_to_text.encode("utf-8"),
                         tweet.in_reply_to_user_id,
                         tweet.is_quote_status,
                         tweet.retweeted,
                         tweet.contributors,
                         tweet.author.screen_name.encode("utf-8"),
                         '@' + tweet.author.name.encode("utf-8"),
                         tweet.author.id,
                         'https://twitter.com/' + tweet.author.screen_name.encode("utf-8"),
                         tweet.author.friends_count,
                         tweet.author.followers_count,
                         tweet.author.statuses_count,
                         tweet.author.description.encode("utf-8"),
                         tweet.author.location.encode("utf-8")]

            tweetData = ['NA' if x is None else x for x in tweetData]

            if "RT" in tweet.full_text.encode("utf-8"):
                left_text = tweet.full_text.encode("utf-8").partition(":")[0]
                tweetData.append(left_text[2:])
            else:
                tweetData.append("")
            outtweets.append(tweetData)
        except tweepy.RateLimitError:
            print('waiting for 5 minutes due to rate limit')
            time.sleep(5 * 60)
            continue

        except StopIteration:
            break

    # here the data, which is currently saved in the memory (RAM), is written to a csv file
    with open('%s_tweets.csv' % screen_name, 'wb') as f:
        writer = csv.writer(f,delimiter='\t')
        # this is written once for the toprow, the header
        writer.writerow(["id", "created_at", "text", "retweet count","favorite count","source","tweet url",
                         "in_reply_to_screen_name", "in_reply_to_status_id","in_reply_to_status_text", "in_reply_to_user_id",
                         "is_quote_status", "retweeted", "contributors",
                         "screen_name","name","author id", "profile url", "friends_count", "followers_count",
                         "statuses_count", "description", "location","retweeted from"])

        # here the data is actually saved
        writer.writerows(outtweets)
    pass

def get_all_friends(screen_name):
        # authorisation
        auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
        auth.set_access_token(access_token, access_secret)
        api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)

        # look up user using screen name
        try:
            user = api.lookup_users(screen_names=[screen_name])
            # choose first occurrence of user in list
            # note that this might lead to errors, if multiple users are found, it is not necessarly the
            # first occurence one is looking for
            # for the archives you passed me this was not a problem, since apparently the data you got is correct
            # and makes sense
            user = user[0]
        except:
            # results in error if name not found
            print('screen name not found')

        friends = []

        friend_list = api.friends_ids(user.id)
        print('number of friends to fetch in total: ')
        print(len(friend_list))
        for page in tqdm(tweepy.Cursor(api.friends_ids,user.id, wait_on_rate_limit=True,
                                    wait_on_rate_limit_notify=True).pages()):

            for friend_id in tqdm(page):
                try:
                    # here again
                    friend = api.lookup_users(user_ids=[friend_id])[0]
                    friends.append([friend.screen_name.encode("utf-8"),
                                '@'+friend.name.encode("utf-8"),
                                friend.id,
                                'https://twitter.com/'+friend.screen_name.encode("utf-8"),
                                friend.friends_count,
                                friend.followers_count,
                                friend.statuses_count,
                                friend.description.encode("utf-8")+" ",
                                friend.location.encode("utf-8")+" "
                                ])
                except tweepy.RateLimitError:
                    print('waiting for 5 minutes due to rate limit')
                    time.sleep(5 * 60)
                    continue
                except StopIteration:
                    break


        # write the csv
        with open('%s_friends.csv' % screen_name, 'wb') as f:
            writer = csv.writer(f, delimiter='\t')
            writer.writerow(["screen_name","name","id", "profile url",
                             "friends_count", "followers_count", "statuses_count", "description", "location",])
            writer.writerows(friends)
        pass


def get_info_list(list):
    # authorisation
    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
    auth.set_access_token(access_token, access_secret)
    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)
    friends = []
    friend_list = list
    not_found = []

    print('number of friends to fetch in total: ')
    print(len(friend_list))
    for friend_id in tqdm(friend_list):
        try:
            try:
                friend = api.get_user(friend_id)
                friends.append([friend.screen_name.encode("utf-8"),
                                '@' + friend.name.encode("utf-8"),
                                friend.id,
                                'https://twitter.com/' + friend.screen_name.encode("utf-8"),
                                friend.friends_count,
                                friend.followers_count,
                                friend.statuses_count,
                                friend.description.encode("utf-8") + " ",
                                friend.location.encode("utf-8") + " "
                                ])
            except:
                not_found.append(friend_id)

        except tweepy.RateLimitError:
            print('waiting for 5 minutes due to rate limit')
            time.sleep(5 * 60)
            continue
        except StopIteration:
            break

    # write the csv
    with open('twitter_extra.csv', 'wb') as f:
        writer = csv.writer(f, delimiter='\t')
        writer.writerow(["screen_name", "name", "id", "profile url",
                         "friends_count", "followers_count", "statuses_count", "description", "location", ])
        writer.writerows(friends)

    return not_found

def get_all_favorites(screen_name):
    # authorisation
    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
    auth.set_access_token(access_token, access_secret)
    api = tweepy.API(auth)

    # look up user using screen name
    try:
        user = api.lookup_users(screen_names=[screen_name])
        # choose first occurrence of user in list
      
        user = user[0]
    except:
        print('screen name not found')



    outtweets = []
    for page in tqdm(tweepy.Cursor(api.favorites, id=user.id, wait_on_rate_limit=True,
                              wait_on_rate_limit_notify=True, count=20).pages()):
        for tweet in tqdm(page):
            if tweet.in_reply_to_status_id:
                try:
                    replied_to_text = api.get_status(tweet.in_reply_to_status_id,tweet_mode='extended').full_text
                except:
                    replied_to_text = "NA"
            else:
                replied_to_text = "NA";
            try:
                tweet = api.get_status(tweet.id,tweet_mode='extended')
                tweetData = [tweet.id_str.encode('utf-8'),
                             tweet.created_at, tweet.full_text.encode("utf-8"),
                             tweet.retweet_count, tweet.favorite_count,
                             tweet.source.encode('utf-8'),'https://twitter.com/'+tweet.author.screen_name.encode("utf-8")+'/status/'+
                             str(tweet.id),
                             tweet.in_reply_to_screen_name,
                             tweet.in_reply_to_status_id,
                             replied_to_text.encode("utf-8"),
                             tweet.in_reply_to_user_id,
                             tweet.is_quote_status,
                             tweet.retweeted,
                             tweet.contributors,
                             tweet.author.screen_name.encode("utf-8"),
                             '@'+tweet.author.name.encode("utf-8"),
                             tweet.author.id,
                             'https://twitter.com/'+tweet.author.screen_name.encode("utf-8"),
                             tweet.author.friends_count,
                             tweet.author.followers_count,
                             tweet.author.statuses_count,
                             tweet.author.description.encode("utf-8")+" ",
                             tweet.author.location.encode("utf-8")+" "]

                tweetData = ['NA' if x is None else x for x in tweetData]

                outtweets.append(tweetData)
            except tweepy.RateLimitError:
                print('waiting for 5 minutes due to rate limit')
                time.sleep(5*60)
                continue
            except StopIteration:
                break



    # write the csv
    with open('%s_favorites.csv' % screen_name, 'wb') as f:
        writer = csv.writer(f,delimiter='\t')
        writer.writerow(["id", "created_at", "text", "retweet count","favorite count","source","tweet url",
                         "in_reply_to_screen_name","in_reply_to_status_id","in_reply_to_status_text","in_reply_to_user_id",
                         "is_quote_status","retweeted","contributors",
                         "screen_name","name","id", "profile url", "friends_count", "followers_count",
                         "statuses_count", "description", "location"])
        writer.writerows(outtweets)

    pass





if __name__ == '__main__':
    # this is executed when script called, from here the functions defined above are called
    # list of accounts to process
    scrap_these_accounts = ["GC_Archives", "bristolarchives", "TheIronRoom", "isg_mannheim", "StadtA_Muenchen"]

    # here is function called which that gets all the tweets
    # the for loop loops over all entries of scrap_these_accounts
    for account in tqdm(scrap_these_accounts):
        # print is an easy way to give feedback to the user of what the program is currently doing
        print('fetching: ')
        print(account)
        # this is the actual function call of the function defined above
        get_all_tweets(account)

    # here is the function called which gets all the friends. as above, every entry in scrap_these_accounts
    for account in tqdm(scrap_these_accounts):
        print('Getting friends of: ' + str(account))
        get_all_friends(account);

    # here is the function called which gets all favourites of an account, rest same as above
    for account in tqdm(scrap_these_accounts):
        print('Getting favorites of: ' + str(account))
        get_all_favorites(account);

    # here is the function called which gets specific information of a specific account
    friends_to_get = ['bergfrau11', 'DerExperte', 'BirminghamPride', 'BlaiseMuseum', 'CfDHoH', 'BR24', 'InspireSW1', 'SophiaThakur', 'BM_AG', 'BMT_Photo', 'celsancfest', 'CineRedis', 'thomasjvincent', 'CommunitiesNI', 'digital_danach', 'EDACS_UoB', 'filminuk_BFC', 'BrisFilmOffice', 'WECILBristol', 'TRBLearning', 'historyinmoment', 'HonorsCarolina', 'IbolyaFeher', 'IndiDeol', 'chight', 'VdALVSachsen', 'ArchCentre', 'marks_jodie', 'PippaGoldfinger', 'parteigaenger', 'StadtMuenchen', 'AWM_Muenchen', 'watershed', 'LettFromBaghdad', 'susie_dent', 'DigiWomenM', 'greenspacescot', 'ChrisAFRIN', 'gilliannd', 'NatFedParks', 'ParksAllianceUK', 'FieldsInTrust ', 'DrewBennellick ', 'PlayScotland ', 'GreenFlagAward ', 'Go2PlayScotland ', 'exerciseworks', 'Locallearning', 'stokes_croft', 'VisitSCroft', 'BristolCouncil', 'VisitBristol', 'bristol247 ', 'BristolPost', 'LouiseM_BMT', 'Colston_Hall', 'laura_culture', 'MarvinJRees', 'MrTimDunn', 'archidave', 'RGIArt', 'RoSPA', 'siwiarchiv', 'WobIntosh', 'KarstenKuehnel', 'zauderhaft', 'Berwinkel', 'SZ_Muenchen', 'GreenCityeV', 'EstherWidmann', 'theboysbrigade', 'ArchivesNZ', 'theflyingeditor', 'kwamekweiarmah', 'UHBristolNHS', 'RCNLibraries', 'theRCN', 'unibirmingham', 'uschaefer', 'Alfred996', 'cranlife', 'ARAScot', 'nlskelvinhall', 'LostGlasgow', 'ARTPARKGLASGOW', 'UofGlasgowASC', 'KelvinHall16', 'TheScotsman', 'SoulCityArts', 'AffinitySutton', 'Trueformproject', 'EDACS_UoB', 'frl_anni', 'Thalkirchen', 'GenchatDe', 'SLUBdresden', 'hannover', 'hevmckay', 'JoergKoglin', 'NorthBristolNHS', 'Radio_Arabella', 'RadioArabella', 'Erlkanzler', 'VdALVSachsen', 'EDLC', 'FinzelsReach', 'KerstinKitzmann', 'BridgemanImages', 'WoodbrookeUK', 'uwecurating', 'isaacblease', 'BlackSWNet', 'MadgeDresser', 'EdsonBurton', 'FulbrightSchlrs', 'BristolUni', 'BGALondon', 'UBPnetwork', 'ColourfulHeritage', 'ktaines', 'jacklatimer', 'JoeARWright', 'johanoomen', 'openbeelden', 'JStanggassinger', 'kate_rumbold', 'Planet_History', 'queensparkfc', 'newlanarkwhs', 'MancLibraries', 'MilesTeaCoffee', 'SideGallery', 'StateRecordsSA', 'JackieKayPoet', 'Radical_Glasgow', '_Diffusion', 'Guardian', 'th_schmid', 'mshed', 'ASPolice', 'CaPnetworkUK', 'Kenco_Mojo', 'metpoliceuk', 'WMAWP', 'Thursley', 'muelleroertel', 'sebastian_post', 'BirlinnBooks', 'OxLifeWriting', 'HootsmaRoots', 'BernerOberland', 'GlasPrintStudio']
    # this is the actual function call. note that one can pass a list, also note that the accounts (friends) that can not be found
    # are returned into not_found and later written to a txt file
    not_found = get_info_list(friends_to_get)
    thefile = open('test.txt', 'w')
    for item in not_found:
        thefile.write("%s\n" % item)

